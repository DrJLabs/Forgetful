input {
  # Filebeat input
  beats {
    port => 5044
  }
  
  # Direct syslog input
  syslog {
    port => 5000
  }
  
  # HTTP input for application logs
  http {
    port => 8080
    codec => json
  }
  
  # TCP input for structured logs
  tcp {
    port => 5001
    codec => json_lines
  }
}

filter {
  # Add timestamp if not present
  if ![timestamp] {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }
  
  # Parse Docker container logs
  if [docker][container][name] {
    # Extract service name from container name
    if [docker][container][name] =~ /^(mem0|openmemory-mcp|openmemory-ui|postgres-mem0|neo4j-mem0)/ {
      grok {
        match => { "[docker][container][name]" => "^(?<service>[^-]+)(-.*)?$" }
      }
    }
    
    # Add service labels
    if [service] == "mem0" {
      mutate {
        add_field => { "service_type" => "api" }
        add_field => { "team" => "backend" }
        add_field => { "tier" => "application" }
      }
    }
    
    if [service] == "openmemory" {
      mutate {
        add_field => { "service_type" => "api" }
        add_field => { "team" => "backend" }
        add_field => { "tier" => "application" }
      }
    }
    
    if [service] == "postgres" {
      mutate {
        add_field => { "service_type" => "database" }
        add_field => { "team" => "database" }
        add_field => { "tier" => "data" }
      }
    }
    
    if [service] == "neo4j" {
      mutate {
        add_field => { "service_type" => "database" }
        add_field => { "team" => "database" }
        add_field => { "tier" => "data" }
      }
    }
  }
  
  # Parse application logs from mem0 API
  if [service] == "mem0" {
    # Parse JSON logs
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "app_log"
      }
    }
    
    # Parse Python logs
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp} - %{LOGLEVEL:log_level} - %{GREEDYDATA:log_message}" 
      }
    }
    
    # Parse HTTP request logs
    if [message] =~ /HTTP/ {
      grok {
        match => { 
          "message" => "%{WORD:method} %{URIPATH:path}(?:%{URIPARAM:params})? HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:response_size} %{NUMBER:response_time:float}" 
        }
      }
      
      # Categorize HTTP response codes
      if [response_code] {
        if [response_code] >= 200 and [response_code] < 300 {
          mutate { add_field => { "response_category" => "success" } }
        } else if [response_code] >= 300 and [response_code] < 400 {
          mutate { add_field => { "response_category" => "redirect" } }
        } else if [response_code] >= 400 and [response_code] < 500 {
          mutate { add_field => { "response_category" => "client_error" } }
        } else if [response_code] >= 500 {
          mutate { add_field => { "response_category" => "server_error" } }
        }
      }
    }
    
    # Parse memory operations
    if [message] =~ /memory_operation/ {
      grok {
        match => { 
          "message" => "memory_operation:(?<operation_type>\w+) user_id:(?<user_id>\w+) status:(?<operation_status>\w+) duration:(?<operation_duration>\d+\.?\d*)" 
        }
      }
      
      mutate {
        add_field => { "event_type" => "memory_operation" }
        convert => { "operation_duration" => "float" }
      }
    }
    
    # Parse vector search operations
    if [message] =~ /vector_search/ {
      grok {
        match => { 
          "message" => "vector_search query:\"(?<search_query>[^\"]+)\" results:(?<result_count>\d+) duration:(?<search_duration>\d+\.?\d*)" 
        }
      }
      
      mutate {
        add_field => { "event_type" => "vector_search" }
        convert => { "result_count" => "integer" }
        convert => { "search_duration" => "float" }
      }
    }
  }
  
  # Parse PostgreSQL logs
  if [service] == "postgres" {
    # Parse PostgreSQL log format
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:pg_timestamp} \[%{NUMBER:pid}\] %{WORD:pg_severity}: %{GREEDYDATA:pg_message}" 
      }
    }
    
    # Parse slow queries
    if [pg_message] =~ /duration:/ {
      grok {
        match => { 
          "pg_message" => "duration: (?<query_duration>\d+\.?\d*) ms.*statement: (?<sql_statement>.*)" 
        }
      }
      
      mutate {
        add_field => { "event_type" => "slow_query" }
        convert => { "query_duration" => "float" }
      }
    }
    
    # Parse connection logs
    if [pg_message] =~ /connection/ {
      grok {
        match => { 
          "pg_message" => "connection (?<connection_action>\w+):.*user=(?<db_user>\w+) database=(?<database>\w+)" 
        }
      }
      
      mutate {
        add_field => { "event_type" => "connection" }
      }
    }
  }
  
  # Parse Neo4j logs
  if [service] == "neo4j" {
    # Parse Neo4j log format
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:neo4j_timestamp} %{LOGLEVEL:neo4j_level} %{GREEDYDATA:neo4j_message}" 
      }
    }
    
    # Parse Cypher queries
    if [neo4j_message] =~ /Cypher/ {
      grok {
        match => { 
          "neo4j_message" => ".*runtime=(?<query_runtime>\d+\.?\d*) ms.*query=(?<cypher_query>.*)" 
        }
      }
      
      mutate {
        add_field => { "event_type" => "cypher_query" }
        convert => { "query_runtime" => "float" }
      }
    }
  }
  
  # Parse OpenMemory MCP logs
  if [service] == "openmemory" {
    # Parse FastAPI logs
    if [message] =~ /uvicorn/ {
      grok {
        match => { 
          "message" => ".*INFO.*uvicorn.*(?<client_ip>\d+\.\d+\.\d+\.\d+).*\"(?<method>\w+) (?<path>[^\"]+).*\" (?<status_code>\d+)" 
        }
      }
      
      mutate {
        add_field => { "event_type" => "http_request" }
      }
    }
    
    # Parse MCP protocol messages
    if [message] =~ /MCP/ {
      grok {
        match => { 
          "message" => "MCP (?<mcp_action>\w+):.*method:(?<mcp_method>\w+).*duration:(?<mcp_duration>\d+\.?\d*)" 
        }
      }
      
      mutate {
        add_field => { "event_type" => "mcp_protocol" }
        convert => { "mcp_duration" => "float" }
      }
    }
  }
  
  # Add environment information
  mutate {
    add_field => { "environment" => "production" }
    add_field => { "cluster" => "mem0-stack" }
    add_field => { "region" => "local" }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input", "log" ]
  }
  
  # Convert timestamp fields
  date {
    match => [ "log_timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # Add severity numeric value for sorting
  if [log_level] {
    if [log_level] == "CRITICAL" {
      mutate { add_field => { "severity_value" => "5" } }
    } else if [log_level] == "ERROR" {
      mutate { add_field => { "severity_value" => "4" } }
    } else if [log_level] == "WARNING" {
      mutate { add_field => { "severity_value" => "3" } }
    } else if [log_level] == "INFO" {
      mutate { add_field => { "severity_value" => "2" } }
    } else if [log_level] == "DEBUG" {
      mutate { add_field => { "severity_value" => "1" } }
    }
    
    mutate {
      convert => { "severity_value" => "integer" }
    }
  }
  
  # Add request ID correlation
  if [message] =~ /request_id:/ {
    grok {
      match => { "message" => ".*request_id:(?<request_id>[a-zA-Z0-9-]+)" }
    }
  }
  
  # Add user ID correlation
  if [message] =~ /user_id:/ {
    grok {
      match => { "message" => ".*user_id:(?<user_id>[a-zA-Z0-9-]+)" }
    }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch-mem0:9200"]
    index => "mem0-stack-logs-%{+YYYY.MM.dd}"
    template_name => "mem0-stack-template"
    template => "/usr/share/logstash/templates/mem0-stack-template.json"
    template_overwrite => true
  }
  
  # Output to separate indices by service
  if [service] {
    elasticsearch {
      hosts => ["elasticsearch-mem0:9200"]
      index => "mem0-stack-%{service}-logs-%{+YYYY.MM.dd}"
    }
  }
  
  # Output errors to separate index
  if [log_level] == "ERROR" or [log_level] == "CRITICAL" {
    elasticsearch {
      hosts => ["elasticsearch-mem0:9200"]
      index => "mem0-stack-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # Output performance metrics to separate index
  if [event_type] in ["memory_operation", "vector_search", "slow_query", "cypher_query"] {
    elasticsearch {
      hosts => ["elasticsearch-mem0:9200"]
      index => "mem0-stack-performance-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output (comment out in production)
  stdout {
    codec => rubydebug
  }
}