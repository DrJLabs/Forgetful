name: "mem0-stack Testing Suite"

on:
  push:
    branches: [ "main", "develop" ]
  pull_request:
    branches: [ "main", "develop" ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

env:
  PYTHONPATH: ${{ github.workspace }}
  TESTING: "true"
  DATABASE_URL: "postgresql://postgres:testpass@localhost:5432/test_db"
  NEO4J_URI: "bolt://localhost:7687"
  NEO4J_USERNAME: "neo4j"
  NEO4J_PASSWORD: "testpass"

jobs:
  test-matrix:
    name: Test Matrix
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        test-suite: ["unit", "integration", "performance"]
        
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      neo4j:
        image: neo4j:5.0
        env:
          NEO4J_AUTH: neo4j/testpass
        options: >-
          --health-cmd "cypher-shell -u neo4j -p testpass 'RETURN 1'"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5
        ports:
          - 7687:7687

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libgeos-dev libpq-dev

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-test.txt
          
          # Install API dependencies
          if [ -f openmemory/api/requirements.txt ]; then
            pip install -r openmemory/api/requirements.txt
          fi
          if [ -f openmemory/api/requirements-test.txt ]; then
            pip install -r openmemory/api/requirements-test.txt
          fi
          
          # Install mem0 dependencies
          if [ -f mem0/pyproject.toml ]; then
            cd mem0 && pip install -e ".[test,graph,vector_stores,llms,extras]"
            cd ..
          fi

      - name: Wait for services
        run: |
          # Wait for PostgreSQL
          until pg_isready -h localhost -p 5432; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done
          
          # Wait for Neo4j
          until nc -z localhost 7687; do
            echo "Waiting for Neo4j..."
            sleep 2
          done

      - name: Run Unit Tests
        if: matrix.test-suite == 'unit'
        run: |
          pytest tests/ -v -m "unit or not integration" \
            --cov=openmemory --cov=shared --cov=mem0 \
            --cov-report=xml:coverage-unit.xml \
            --cov-report=html:htmlcov-unit \
            --cov-report=term-missing \
            --junit-xml=test-results-unit.xml \
            --durations=10

      - name: Run Integration Tests
        if: matrix.test-suite == 'integration'
        run: |
          pytest tests/ openmemory/api/tests/ -v -m "integration" \
            --cov=openmemory --cov=shared \
            --cov-report=xml:coverage-integration.xml \
            --cov-report=html:htmlcov-integration \
            --cov-report=term-missing \
            --junit-xml=test-results-integration.xml \
            --durations=10

      - name: Run Performance Tests
        if: matrix.test-suite == 'performance'
        run: |
          pytest tests/ -v -m "performance" \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-sort=mean \
            --junit-xml=test-results-performance.xml

      - name: Upload Coverage Reports
        uses: codecov/codecov-action@v3
        if: matrix.test-suite != 'performance'
        with:
          file: coverage-${{ matrix.test-suite }}.xml
          flags: ${{ matrix.test-suite }}
          name: codecov-${{ matrix.test-suite }}-py${{ matrix.python-version }}

      - name: Upload Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.test-suite }}-py${{ matrix.python-version }}
          path: |
            test-results-*.xml
            htmlcov-*
            benchmark-results.json
          retention-days: 30

  backend-tests:
    name: Backend API Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          cd openmemory/api
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt

      - name: Run Backend Tests
        run: |
          cd openmemory/api
          pytest tests/ -v \
            --cov=app \
            --cov-report=xml:coverage.xml \
            --cov-report=html:htmlcov \
            --cov-report=term-missing \
            --junit-xml=test-results.xml \
            --cov-fail-under=80

      - name: Upload Backend Coverage
        uses: codecov/codecov-action@v3
        with:
          file: openmemory/api/coverage.xml
          flags: backend
          name: codecov-backend

  frontend-tests:
    name: Frontend UI Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: openmemory/ui/package-lock.json

      - name: Install Dependencies
        run: |
          cd openmemory/ui
          npm ci

      - name: Run Frontend Tests
        run: |
          cd openmemory/ui
          npm run test:ci || echo "Frontend tests not configured yet"

  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: [test-matrix, backend-tests]
    if: always()
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Test Results
        uses: actions/download-artifact@v3
        with:
          path: test-results

      - name: Quality Gate Check
        run: |
          echo "ðŸ” Quality Gate Checks:"
          echo "========================"
          
          # Check if critical tests passed
          if [ "${{ needs.test-matrix.result }}" != "success" ]; then
            echo "âŒ Test matrix failed"
            exit 1
          fi
          
          if [ "${{ needs.backend-tests.result }}" != "success" ]; then
            echo "âŒ Backend tests failed"
            exit 1
          fi
          
          echo "âœ… All quality gates passed"

      - name: Generate Test Report
        run: |
          echo "# Test Summary Report" > test-summary.md
          echo "Generated: $(date)" >> test-summary.md
          echo "" >> test-summary.md
          echo "## Test Results" >> test-summary.md
          echo "- Test Matrix: ${{ needs.test-matrix.result }}" >> test-summary.md
          echo "- Backend Tests: ${{ needs.backend-tests.result }}" >> test-summary.md
          echo "- Frontend Tests: ${{ needs.frontend-tests.result }}" >> test-summary.md
          
          cat test-summary.md

      - name: Upload Test Summary
        uses: actions/upload-artifact@v3
        with:
          name: test-summary
          path: test-summary.md
          retention-days: 30 